{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9454e142",
   "metadata": {},
   "source": [
    "# Facial Emotion Recognition Training (FER-2013)\n",
    "\n",
    "Cleaned and corrected training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d1bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12e6e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataset directories (keep dataset folder in project root)\n",
    "train_dir = \"dataset/train\"\n",
    "val_dir = \"dataset/validation\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95ec0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data augmentation and preprocessing\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(48,48),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=64,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(48,48),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=64,\n",
    "    class_mode=\"categorical\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f71523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CNN Model (FER compatible)\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(48,48,1)),\n",
    "    MaxPooling2D(2,2),\n",
    "\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fce3349",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=30\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a2059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save model architecture and weights\n",
    "model_json = model.to_json()\n",
    "with open(\"facialemotionmodel.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights(\"facialemotionmodel.h5\")\n",
    "\n",
    "print(\"Model saved as facialemotionmodel.json and facialemotionmodel.h5\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}